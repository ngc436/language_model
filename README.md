# Language Models Repository

Current repository contains experiments on language modeling for text classification. 

## Steps to be done
- [x] Prepare train/test/val
- [ ] Get TM results
- [ ] Implement QRNN
- [ ] Implement BiLSTM
- [ ] Implement simple LSTM
- [ ] Add SVM and XgBoost tools
- [ ] Milestone: initial classification results (19 oct.)
- [ ] Implement VAE 
 
 ## Datasets
 
* '/mnt/shdstorage/tmp/classif_tmp/X_train.csv'
* '/mnt/shdstorage/tmp/classif_tmp/X_test.csv'
* '/mnt/shdstorage/tmp/classif_tmp/y_train.csv'
* '/mnt/shdstorage/tmp/classif_tmp/y_test.csv'
 
## Literature

1. Stephen Merity, Nitish Shirish Keskar, and Richard Socher. Regularizing and optimizing LSTM language models. CoRR, abs/1708.02182,  2017.   URL http://arxiv.org/abs/1708.02182.
2. J. Howard and S. Ruder.  Universal language model fine-tuning for text classification. Association for Computational Linguistics (ACL), 2018.
3. Bradbury, J., Merity, S., Xiong, C., and Socher, R. Quasi-Recurrent Neural Networks. arXiv preprint arXiv:1611.01576, 2016.
4. Kutuzov A., Kuzmenko E. (2017) WebVectors: A Toolkit for Building Web Interfaces for Vector Semantic Models. In: Ignatov D. et al. (eds) Analysis of Images, Social Networks and Texts. AIST 2016. Communications in Computer and Information Science, vol 661. Springer, Cham